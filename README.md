# Ollama Chat Application

A chat interface for Ollama using Next.js and FastAPI.

# install requirements
pip install -r requirements.txt

## Project Structure

```
ollama-chat/
├─ backend/         # FastAPI server
├─ frontend/        # Next.js frontend
└─ README.md
```
## run ollama in bacground: 
ollama serve

## Getting Started


3. Install dependencies:
```bash
pip install -r requirements.txt
```


2. Install dependencies:
```bash
npm install
```

3. Run the development server:
```bash
npm run dev
```

The application will be available at http://localhost:3000



Note: Open command promt and run below commands if another process is executing or failed to execute ollama.
  "OLLAMA_HOST=127.0.0.1:11500"

ollama serve 